## Instrumental Variables

**Instrumental Variables** in the context of our school feeding program help us figure out how the program affects attendance rates when other factors might confuse the results. An instrumental variable is something that influences whether a child participates in the program (like whether their school is in a treatment area) but doesn’t directly impact attendance rates except through the program itself. This approach helps isolate the program's true effect on attendance, even if there are other overlapping influences.

Let us now try using the randomized promotion method to evaluate the impact of the school feeding program (SFP) on attendance rates. Imagine the Ministry of Education decides that the feeding program should eventually be made available to all schools nationwide. This is a different situation from the randomized assignment design we’ve considered so far. However, given the logistical realities of scaling the program, you propose an incremental rollout.

To assess its impact, you randomly select a subset of schools (indicated by `promotion_locality`) to receive an intensive promotion campaign aimed at increasing awareness and participation in the feeding program. This campaign includes activities such as community outreach, parent meetings, and tailored communication materials to emphasize the program's benefits. Importantly, the promotion focuses solely on raising awareness and boosting program enrollment, ensuring it does not directly encourage unrelated behaviors that could influence attendance rates. This design ensures the promotion can be used as a valid instrumental variable (IV) for understanding how the feeding program affects attendance rates.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Loading of packages, data, and seed setting here
library(haven)
library(tidyverse)
library(broom)
library(estimatr)
library(fishmethods)
library(kableExtra)
library(MatchIt)
library(modelsummary)
library(pwr)
library(rddensity)
library(skimr)
library(texreg)
library(gtsummary)

# you can read directly from github here --
trans_df <- read_csv("https://raw.githubusercontent.com/vmandela99/blog_vickman/refs/heads/main/posts/M%26E_01_School_Feeding_Causal_inference_%26_Counterfactuals/school_feeding.csv")

theme_set(ggpubr::theme_pubclean())

# subset data to only "eligible" units
df_elig <- trans_df %>%
  filter(eligible == 1)
```

**What was the effect of the promotion campaign upon enrollment?**

*Note you should use the variable* `enrolled_rp` *for this question*

```{r}
m_enroll <- lm_robust(enrolled_rp ~ promotion_locality,
                      clusters = locality_identifier,
                      data = trans_df %>% filter(round == 1))

t_enroll <- tbl_regression(m_enroll, intercept = TRUE) %>%
  add_glance_source_note(
    glance_fun = broom::glance, # Extract model summary
    include = c("adj.r.squared", "r.squared", "nobs") # Add Adjusted R-squared
  )

t_enroll
```

After two years of promotion and program implementation, you find that 41% of students in schools randomly assigned to the promotion campaign are attending school more regularly, compared to only 8% in non-promoted schools.

Because the promoted and non-promoted schools were assigned at random, we can confidently assume that the baseline characteristics of the two groups were similar in the absence of the promotion. This assumption is validated by comparing baseline attendance rates and other school-related characteristics, which showed no significant differences.

From the results in Table 2, the estimated impact of the promotion locality on attendance rates is a significant increase of 41 percentage points (Beta = 0.41, 95% CI \[0.34, 0.48\], p \< 0.001). The intercept (baseline attendance rate in non-promoted schools) was estimated at 8% (Beta = 0.08, 95% CI \[0.04, 0.13\], p = 0.001). The model explains 20% of the variation in attendance rates (Adjusted R² = 0.20), indicating a strong relationship between promotion and improved attendance outcomes.

**Compare baseline attendance rates based upon assignment to promotion.**

```{r}
m_base_attend <- lm_robust(attendance_rate ~ promotion_locality,
                           clusters = locality_identifier,
                           data = trans_df %>% filter(round == 0)
)

t_base_attend <- tbl_regression(m_base_attend, intercept = TRUE) %>%
  add_glance_source_note(
    glance_fun = broom::glance, # Extract model summary
    include = c("adj.r.squared", "r.squared", "nobs") # Add Adjusted R-squared
  ) 
t_base_attend
```

**Estimate the difference in attendance rates by assignment to promotion, in the post-treatment period**

```{r}

m_post_attend <- lm_robust(attendance_rate ~ promotion_locality,
                           clusters = locality_identifier,
                           data = trans_df %>% filter(round == 1)
)

t_post_attend <- tbl_regression(m_post_attend, intercept = TRUE) %>%
  add_glance_source_note(
    glance_fun = broom::glance, # Extract model summary
    include = c("adj.r.squared", "r.squared", "nobs") # Add Adjusted R-squared
  ) 
t_post_attend
```

**Using this attendance rate estimate and the estimated proportion of “compliers”, estimate the LATE/CACE**

### **LATE (Local Average Treatment Effect):**

LATE measures the effect of the program **only on the group that complied with the treatment assignment** (e.g., those who were offered the feeding program and actually participated). It tells us the impact on attendance rates for these participants, not for everyone assigned to the treatment or control groups.

### **CACE (Complier Average Causal Effect):**

CACE is essentially the same as LATE in many contexts, particularly in randomized trials. It focuses on estimating the causal effect of the program for those who adhered to their assignment (e.g., those who were assigned to the treatment and participated, or those in the control who did not access the treatment).

```{r warning=FALSE, message=FALSE}
m_cace <- iv_robust(attendance_rate ~ enrolled_rp |
                      promotion_locality,
                    clusters = locality_identifier,
                    data = trans_df %>% filter(round == 1))

m_cace_wcov <- iv_robust(attendance_rate ~ enrolled_rp + 
                           age_hh + age_sp + educ_hh + educ_sp + 
                           female_hh + indigenous + hhsize + dirtfloor + 
                           bathroom + land + school_distance | 
                           promotion_locality + 
                           age_hh + age_sp + educ_hh + educ_sp + 
                           female_hh + indigenous + hhsize + dirtfloor + 
                           bathroom + land + school_distance ,
                         clusters = locality_identifier,
                         data = trans_df %>% filter(round == 1))


t_cace <- tbl_regression(m_cace, intercept = T)
t_cace_wcov <- tbl_regression(m_cace_wcov, intercept = T)

tbl_merge_cace <-
  tbl_merge(
    tbls = list(t_cace, t_cace_wcov),
    tab_spanner = c("**No Covariate Adjust.**", "**With Covariate Adjust.**")
  )

tbl_merge_cace

```

**Compare baseline attendance rates based upon assignment to promotion**

The baseline attendance rates show that there is no significant difference in attendance rates between schools assigned to the promotion (SFP) and those that were not, as indicated by the promotion locality coefficient of 0.05 with a 95% Confidence Interval (CI) of \[-0.44, 0.53\] and a p-value of 0.9. The p-value is greater than the 0.05 significance level, which means that any differences in baseline attendance are likely due to random variation, not the promotion itself.

**Estimate the difference in attendance rates by assignment to promotion, in the post-treatment period**

The post attendance period shows a significant positive effect on attendance, with a coefficient of 3.3 (95% CI \[2.2, 4.4\], p-value \< 0.001). This suggests that schools assigned to the feeding program promotion saw an increase in attendance rates by about 3.3 percentage points compared to non-promoted schools. The model’s adjusted R² of 0.026 indicates that a small proportion of the variation in attendance is explained by the promotion, but the effect is still statistically significant.

**Using this attendance rate estimate and the estimated proportion of “compliers,” estimate the LATE/CACE**

The Local Average Treatment Effect (LATE) and the Complier Average Causal Effect (CACE) are estimated by considering both unadjusted and adjusted models.

**No Covariate Adjustment:** The coefficient for the promotion locality remains significant (Beta = 8.1, 95% CI \[6.2, 10\], p-value \< 0.001), suggesting that, on average, the promotion led to an 8.1 percentage point increase in attendance for those schools in the promotion locality who complied with the program.

**With Covariate Adjustment:** After adjusting for covariates such as household characteristics and school factors, the effect is slightly higher (Beta = 8.3, 95% CI \[6.7, 10\], p-value \< 0.001), reinforcing the robustness of the promotion’s impact. These results suggest that the school feeding program had a substantial positive impact on attendance rates, particularly for the compliers—those schools that adhered to the promotion. The covariate-adjusted estimates provide additional confidence that the observed effect is not solely driven by confounding factors.

**What are the key conditions for accepting the results from the randomized promotion evaluation of the SFP**

-   **Baseline Equivalence:** The schools in the promoted and non-promoted groups should have similar characteristics before the promotion. The baseline attendance rates in the first table show no significant difference, suggesting this assumption holds true.

-   **Promotion Effectiveness:** The promotion should effectively increase school attendance. This assumption holds in the post-treatment period, where the promoted schools show a significant increase in attendance by 3.3 percentage points.

-   **No Direct Effects on Other Factors:** The promotion should only affect attendance and not other outcomes (such as student performance or health). This assumption cannot be directly tested but is informed by the program's design focusing only on increasing school attendance.

**Should the SFP be Scaled Up Nationally?**

Based on the results from the regression analysis, the school feeding program shows a significant positive impact on attendance rates. The estimated LATE/CACE of 8.3 percentage points suggests a clear benefit from the program. Therefore, the results support scaling the program up nationally, as the program’s effectiveness in improving attendance is statistically significant and substantial.
